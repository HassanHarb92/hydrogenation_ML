{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "851b5c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  unsat_SMILE sat_SMILE     delta_H  nH2    pH2\n",
      "0         C#C        CC  150.735206    2  13.42\n",
      "1         C=O        CO   83.774454    1   6.29\n",
      "2        CC#C       CCC  139.811813    2   9.15\n",
      "3        CC=O       CCO   63.227291    1   4.38\n",
      "4     CC(C)=O    CC(C)O   51.916637    1   3.36\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('gdb9_G4MP2_withdata_hydrogenation_clean.csv')\n",
    "\n",
    "# Display the first few rows of the dataframe to understand its structure\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "29ec0753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rdkit.Chem.Fragments as Fragments\n",
    "import rdkit.Chem as Chem\n",
    "import rdkit.Chem.Crippen as Crippen\n",
    "import rdkit.Chem.Lipinski as Lipinski\n",
    "import rdkit.Chem.rdMolDescriptors as MolDescriptors\n",
    "import rdkit.Chem.Descriptors as Descriptors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from scipy.stats import norm\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C ,WhiteKernel as Wht,Matern as matk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dfb19bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial training data size: 970\n",
      "Unlabeled pool size: 18436\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initial split: 5% for initial training, 95% as unlabeled pool\n",
    "initial_data, unlabeled_pool = train_test_split(df, test_size=0.95, random_state=42)\n",
    "\n",
    "print(\"Initial training data size:\", initial_data.shape[0])\n",
    "print(\"Unlabeled pool size:\", unlabeled_pool.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aa38ea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_chem_mol(mol):\n",
    "    mol_sssr = Chem.GetSSSR(mol)\n",
    "    clogp    = Crippen.MolLogP(mol)\n",
    "    mr       = Crippen.MolMR(mol)\n",
    "    mw       = MolDescriptors.CalcExactMolWt(mol)\n",
    "    tpsa    = MolDescriptors.CalcTPSA(mol)\n",
    "    Chi0n    = MolDescriptors.CalcChi0n(mol)\n",
    "    Chi1n    = MolDescriptors.CalcChi1n(mol)\n",
    "    Chi2n    = MolDescriptors.CalcChi2n(mol)\n",
    "    Chi3n    = MolDescriptors.CalcChi3n(mol)\n",
    "    Chi4n    = MolDescriptors.CalcChi4n(mol)\n",
    "    Chi0v    = MolDescriptors.CalcChi0v(mol)\n",
    "    Chi1v    = MolDescriptors.CalcChi1v(mol)\n",
    "    Chi2v    = MolDescriptors.CalcChi2v(mol)\n",
    "    Chi3v    = MolDescriptors.CalcChi3v(mol)\n",
    "    Chi4v    = MolDescriptors.CalcChi4v(mol)\n",
    "    fracsp3  = MolDescriptors.CalcFractionCSP3(mol)\n",
    "    Hall_Kier_Alpha = MolDescriptors.CalcHallKierAlpha(mol)\n",
    "    Kappa1      = MolDescriptors.CalcKappa1(mol)\n",
    "    Kappa2      = MolDescriptors.CalcKappa2(mol)\n",
    "    Kappa3      = MolDescriptors.CalcKappa3(mol)\n",
    "    LabuteASA   = MolDescriptors.CalcLabuteASA(mol)\n",
    "    Number_Aliphatic_Rings = MolDescriptors.CalcNumAliphaticRings(mol)\n",
    "    Number_Aromatic_Rings = MolDescriptors.CalcNumAromaticRings(mol)\n",
    "    Number_Amide_Bonds = MolDescriptors.CalcNumAmideBonds(mol)\n",
    "    Number_Atom_Stereocenters = MolDescriptors.CalcNumAtomStereoCenters(mol)\n",
    "    Number_BridgeHead_Atoms = MolDescriptors.CalcNumBridgeheadAtoms(mol)\n",
    "    Number_HBA = MolDescriptors.CalcNumHBA(mol)\n",
    "    Number_HBD = MolDescriptors.CalcNumHBD(mol)\n",
    "    Number_Hetero_Atoms = MolDescriptors.CalcNumHeteroatoms(mol)\n",
    "    Number_Hetero_Cycles = MolDescriptors.CalcNumHeterocycles(mol)\n",
    "    Number_Rings = MolDescriptors.CalcNumRings(mol)\n",
    "    Number_Rotatable_Bonds = MolDescriptors.CalcNumRotatableBonds(mol)\n",
    "    Number_Spiro = MolDescriptors.CalcNumSpiroAtoms(mol)\n",
    "    Number_Saturated_Rings = MolDescriptors.CalcNumSaturatedRings(mol)\n",
    "    Number_Heavy_Atoms = Lipinski.HeavyAtomCount(mol)\n",
    "    Number_NH_OH = Lipinski.NHOHCount(mol)\n",
    "    Number_N_O = Lipinski.NOCount(mol)\n",
    "    Number_Valence_Electrons = Descriptors.NumValenceElectrons(mol)\n",
    "    Max_Partial_Charge = Descriptors.MaxPartialCharge(mol)\n",
    "    Min_Partial_Charge = Descriptors.MinPartialCharge(mol)\n",
    "\n",
    "    return mol_sssr, clogp, mr, mw, tpsa, Chi0n, Chi1n, Chi2n, Chi3n, Chi4n, Chi0v, Chi1v, Chi2v, Chi3v, Chi4v, fracsp3, Hall_Kier_Alpha,Kappa1, Kappa2, Kappa3, LabuteASA, Number_Aliphatic_Rings, Number_Aromatic_Rings, Number_Amide_Bonds, Number_Atom_Stereocenters, Number_BridgeHead_Atoms, Number_HBA, Number_HBD, Number_Hetero_Atoms, Number_Hetero_Cycles, Number_Rings, Number_Rotatable_Bonds, Number_Spiro, Number_Saturated_Rings, Number_Heavy_Atoms, Number_NH_OH, Number_N_O, Number_Valence_Electrons, Max_Partial_Charge, Min_Partial_Charge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8262b554",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_descriptors_for_dataframe(df, smiles_column):\n",
    "    # Initialize lists to hold descriptors\n",
    "    descriptors = []\n",
    "\n",
    "    # Loop through SMILES strings in the dataframe\n",
    "    for smiles in df[smiles_column]:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol:  # check if mol conversion is successful\n",
    "            descriptors.append(evaluate_chem_mol(mol))\n",
    "        else:\n",
    "            # Append None or NaN for molecules that fail conversion\n",
    "            descriptors.append([None]*40)  # 40 being the number of descriptors\n",
    "\n",
    "    # Convert list of descriptors to DataFrame\n",
    "    desc_df = pd.DataFrame(descriptors, columns=[\n",
    "        'mol_sssr', 'clogp', 'mr', 'mw', 'tpsa', 'Chi0n', 'Chi1n', 'Chi2n', 'Chi3n', 'Chi4n', \n",
    "        'Chi0v', 'Chi1v', 'Chi2v', 'Chi3v', 'Chi4v', 'fracsp3', 'Hall_Kier_Alpha','Kappa1', \n",
    "        'Kappa2', 'Kappa3', 'LabuteASA', 'Number_Aliphatic_Rings', 'Number_Aromatic_Rings', \n",
    "        'Number_Amide_Bonds', 'Number_Atom_Stereocenters', 'Number_BridgeHead_Atoms', 'Number_HBA', \n",
    "        'Number_HBD', 'Number_Hetero_Atoms', 'Number_Hetero_Cycles', 'Number_Rings', 'Number_Rotatable_Bonds', \n",
    "        'Number_Spiro', 'Number_Saturated_Rings', 'Number_Heavy_Atoms', 'Number_NH_OH', 'Number_N_O', \n",
    "        'Number_Valence_Electrons', 'Max_Partial_Charge', 'Min_Partial_Charge'\n",
    "    ])\n",
    "    \n",
    "    return pd.concat([df, desc_df], axis=1)\n",
    "\n",
    "# Compute descriptors for the entire dataset\n",
    "df = compute_descriptors_for_dataframe(df, 'unsat_SMILE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9e02ee9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "\n",
    "# Split data into initial training set and unlabeled pool\n",
    "initial_idx = np.random.choice(range(len(df)), size=970, replace=False)\n",
    "pool_idx = [i for i in range(len(df)) if i not in initial_idx]\n",
    "\n",
    "X = df.iloc[:, 5:].values  # Assuming descriptors start from the 5th column\n",
    "y = df['delta_H'].values\n",
    "\n",
    "X_initial = X[initial_idx]\n",
    "y_initial = y[initial_idx]\n",
    "X_pool = X[pool_idx]\n",
    "y_pool = y[pool_idx]\n",
    "\n",
    "# Initialize Gaussian Process\n",
    "kernel = DotProduct() + WhiteKernel()\n",
    "gp = GaussianProcessRegressor(kernel=kernel, random_state=1)\n",
    "\n",
    "# Train on the initial data\n",
    "gp.fit(X_initial, y_initial)\n",
    "\n",
    "# Make predictions on the pool\n",
    "predictions, std_dev = gp.predict(X_pool, return_std=True)\n",
    "\n",
    "# Let's say we want to add 100 least confident points to our training data\n",
    "uncertainty_idx = np.argsort(std_dev)[-100:]\n",
    "\n",
    "# Append the uncertain points to the initial data\n",
    "X_initial = np.vstack([X_initial, X_pool[uncertainty_idx]])\n",
    "y_initial = np.hstack([y_initial, y_pool[uncertainty_idx]])\n",
    "\n",
    "# Remove the uncertain points from the pool\n",
    "X_pool = np.delete(X_pool, uncertainty_idx, axis=0)\n",
    "y_pool = np.delete(y_pool, uncertainty_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa454df",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iterations = 20  # You can change this to any desired number\n",
    "n_to_add_each_iter = 500  # Number of points to add from the pool to training set in each iteration\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    # Train Gaussian Process on current training data\n",
    "    gp.fit(X_initial, y_initial)\n",
    "\n",
    "    # Predict on the unlabeled pool\n",
    "    predictions, std_dev = gp.predict(X_pool, return_std=True)\n",
    "\n",
    "    # Select points where the model is least confident (highest standard deviation)\n",
    "    uncertainty_idx = np.argsort(std_dev)[-n_to_add_each_iter:]\n",
    "\n",
    "    # Append the uncertain points to the training data\n",
    "    X_initial = np.vstack([X_initial, X_pool[uncertainty_idx]])\n",
    "    y_initial = np.hstack([y_initial, y_pool[uncertainty_idx]])\n",
    "\n",
    "    # Remove the uncertain points from the pool\n",
    "    X_pool = np.delete(X_pool, uncertainty_idx, axis=0)\n",
    "    y_pool = np.delete(y_pool, uncertainty_idx)\n",
    "\n",
    "    # Optionally, print progress\n",
    "    print(f\"Iteration {i+1}/{n_iterations} complete. Training set size: {len(y_initial)}\")\n",
    "\n",
    "print(\"Active learning process complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bd9263be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Hydrogenation Enthalpy (kJ/mol H2) for the new molecule: -73.11803639174408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hassan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Cc1cc2ccccc2o1\n",
    "\n",
    "new_molecule_smiles = \"Cc1ccccc1Cc1ccncc1\"  # Replace with your SMILES string\n",
    "\n",
    "# Convert to RDKit mol object\n",
    "new_mol = Chem.MolFromSmiles(new_molecule_smiles)\n",
    "\n",
    "# Check if the conversion is successful\n",
    "if new_mol:\n",
    "    new_molecule_descriptors = evaluate_chem_mol(new_mol)\n",
    "else:\n",
    "    raise ValueError(\"Invalid SMILES string or molecule conversion failed.\")\n",
    "\n",
    "# Convert descriptors to a numpy array and reshape for single sample prediction\n",
    "new_molecule_descriptors = np.array(new_molecule_descriptors).reshape(1, -1)\n",
    "\n",
    "# Splitting the data into training and test sets\n",
    "train_data, test_data = train_test_split(df, test_size=0.1, random_state=42)\n",
    "\n",
    "# List of descriptor columns (you've defined these when you computed descriptors)\n",
    "descriptor_cols = [\n",
    "    'mol_sssr', 'clogp', 'mr', 'mw', 'tpsa', 'Chi0n', 'Chi1n', 'Chi2n', 'Chi3n', 'Chi4n', \n",
    "    'Chi0v', 'Chi1v', 'Chi2v', 'Chi3v', 'Chi4v', 'fracsp3', 'Hall_Kier_Alpha','Kappa1', \n",
    "    'Kappa2', 'Kappa3', 'LabuteASA', 'Number_Aliphatic_Rings', 'Number_Aromatic_Rings', \n",
    "    'Number_Amide_Bonds', 'Number_Atom_Stereocenters', 'Number_BridgeHead_Atoms', 'Number_HBA', \n",
    "    'Number_HBD', 'Number_Hetero_Atoms', 'Number_Hetero_Cycles', 'Number_Rings', 'Number_Rotatable_Bonds', \n",
    "    'Number_Spiro', 'Number_Saturated_Rings', 'Number_Heavy_Atoms', 'Number_NH_OH', 'Number_N_O', \n",
    "    'Number_Valence_Electrons', 'Max_Partial_Charge', 'Min_Partial_Charge'\n",
    "]\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data descriptors\n",
    "scaler.fit(train_data[descriptor_cols])\n",
    "\n",
    "new_molecule_descriptors_scaled = scaler.transform(new_molecule_descriptors)\n",
    "\n",
    "\n",
    "predicted_delta_H = gp.predict(new_molecule_descriptors_scaled)\n",
    "print(f\"Predicted Hydrogenation Enthalpy (kJ/mol H2) for the new molecule: {predicted_delta_H[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d279bd91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b5eb56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce64bc2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f12e138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea4de7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
