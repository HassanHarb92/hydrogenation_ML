{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "851b5c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  unsat_SMILE sat_SMILE     delta_H  nH2    pH2\n",
      "0         C#C        CC  150.735206    2  13.42\n",
      "1         C=O        CO   83.774454    1   6.29\n",
      "2        CC#C       CCC  139.811813    2   9.15\n",
      "3        CC=O       CCO   63.227291    1   4.38\n",
      "4     CC(C)=O    CC(C)O   51.916637    1   3.36\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('gdb9_G4MP2_withdata_hydrogenation_clean.csv')\n",
    "\n",
    "# Display the first few rows of the dataframe to understand its structure\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "29ec0753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rdkit.Chem.Fragments as Fragments\n",
    "import rdkit.Chem as Chem\n",
    "import rdkit.Chem.Crippen as Crippen\n",
    "import rdkit.Chem.Lipinski as Lipinski\n",
    "import rdkit.Chem.rdMolDescriptors as MolDescriptors\n",
    "import rdkit.Chem.Descriptors as Descriptors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from scipy.stats import norm\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C ,WhiteKernel as Wht,Matern as matk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dfb19bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial training data size: 970\n",
      "Unlabeled pool size: 18436\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initial split: 5% for initial training, 95% as unlabeled pool\n",
    "initial_data, unlabeled_pool = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Initial training data size:\", initial_data.shape[0])\n",
    "print(\"Unlabeled pool size:\", unlabeled_pool.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "aa38ea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_chem_mol(mol):\n",
    "    mol_sssr = Chem.GetSSSR(mol)\n",
    "    clogp    = Crippen.MolLogP(mol)\n",
    "    mr       = Crippen.MolMR(mol)\n",
    "    mw       = MolDescriptors.CalcExactMolWt(mol)\n",
    "    tpsa    = MolDescriptors.CalcTPSA(mol)\n",
    "    Chi0n    = MolDescriptors.CalcChi0n(mol)\n",
    "    Chi1n    = MolDescriptors.CalcChi1n(mol)\n",
    "    Chi2n    = MolDescriptors.CalcChi2n(mol)\n",
    "    Chi3n    = MolDescriptors.CalcChi3n(mol)\n",
    "    Chi4n    = MolDescriptors.CalcChi4n(mol)\n",
    "    Chi0v    = MolDescriptors.CalcChi0v(mol)\n",
    "    Chi1v    = MolDescriptors.CalcChi1v(mol)\n",
    "    Chi2v    = MolDescriptors.CalcChi2v(mol)\n",
    "    Chi3v    = MolDescriptors.CalcChi3v(mol)\n",
    "    Chi4v    = MolDescriptors.CalcChi4v(mol)\n",
    "    fracsp3  = MolDescriptors.CalcFractionCSP3(mol)\n",
    "    Hall_Kier_Alpha = MolDescriptors.CalcHallKierAlpha(mol)\n",
    "    Kappa1      = MolDescriptors.CalcKappa1(mol)\n",
    "    Kappa2      = MolDescriptors.CalcKappa2(mol)\n",
    "    Kappa3      = MolDescriptors.CalcKappa3(mol)\n",
    "    LabuteASA   = MolDescriptors.CalcLabuteASA(mol)\n",
    "    Number_Aliphatic_Rings = MolDescriptors.CalcNumAliphaticRings(mol)\n",
    "    Number_Aromatic_Rings = MolDescriptors.CalcNumAromaticRings(mol)\n",
    "    Number_Amide_Bonds = MolDescriptors.CalcNumAmideBonds(mol)\n",
    "    Number_Atom_Stereocenters = MolDescriptors.CalcNumAtomStereoCenters(mol)\n",
    "    Number_BridgeHead_Atoms = MolDescriptors.CalcNumBridgeheadAtoms(mol)\n",
    "    Number_HBA = MolDescriptors.CalcNumHBA(mol)\n",
    "    Number_HBD = MolDescriptors.CalcNumHBD(mol)\n",
    "    Number_Hetero_Atoms = MolDescriptors.CalcNumHeteroatoms(mol)\n",
    "    Number_Hetero_Cycles = MolDescriptors.CalcNumHeterocycles(mol)\n",
    "    Number_Rings = MolDescriptors.CalcNumRings(mol)\n",
    "    Number_Rotatable_Bonds = MolDescriptors.CalcNumRotatableBonds(mol)\n",
    "    Number_Spiro = MolDescriptors.CalcNumSpiroAtoms(mol)\n",
    "    Number_Saturated_Rings = MolDescriptors.CalcNumSaturatedRings(mol)\n",
    "    Number_Heavy_Atoms = Lipinski.HeavyAtomCount(mol)\n",
    "    Number_NH_OH = Lipinski.NHOHCount(mol)\n",
    "    Number_N_O = Lipinski.NOCount(mol)\n",
    "    Number_Valence_Electrons = Descriptors.NumValenceElectrons(mol)\n",
    "    Max_Partial_Charge = Descriptors.MaxPartialCharge(mol)\n",
    "    Min_Partial_Charge = Descriptors.MinPartialCharge(mol)\n",
    "\n",
    "    return mol_sssr, clogp, mr, mw, tpsa, Chi0n, Chi1n, Chi2n, Chi3n, Chi4n, Chi0v, Chi1v, Chi2v, Chi3v, Chi4v, fracsp3, Hall_Kier_Alpha,Kappa1, Kappa2, Kappa3, LabuteASA, Number_Aliphatic_Rings, Number_Aromatic_Rings, Number_Amide_Bonds, Number_Atom_Stereocenters, Number_BridgeHead_Atoms, Number_HBA, Number_HBD, Number_Hetero_Atoms, Number_Hetero_Cycles, Number_Rings, Number_Rotatable_Bonds, Number_Spiro, Number_Saturated_Rings, Number_Heavy_Atoms, Number_NH_OH, Number_N_O, Number_Valence_Electrons, Max_Partial_Charge, Min_Partial_Charge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8262b554",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_descriptors_for_dataframe(df, smiles_column):\n",
    "    # Initialize lists to hold descriptors\n",
    "    descriptors = []\n",
    "\n",
    "    # Loop through SMILES strings in the dataframe\n",
    "    for smiles in df[smiles_column]:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol:  # check if mol conversion is successful\n",
    "            descriptors.append(evaluate_chem_mol(mol))\n",
    "        else:\n",
    "            # Append None or NaN for molecules that fail conversion\n",
    "            descriptors.append([None]*40)  # 40 being the number of descriptors\n",
    "\n",
    "    # Convert list of descriptors to DataFrame\n",
    "    desc_df = pd.DataFrame(descriptors, columns=[\n",
    "        'mol_sssr', 'clogp', 'mr', 'mw', 'tpsa', 'Chi0n', 'Chi1n', 'Chi2n', 'Chi3n', 'Chi4n', \n",
    "        'Chi0v', 'Chi1v', 'Chi2v', 'Chi3v', 'Chi4v', 'fracsp3', 'Hall_Kier_Alpha','Kappa1', \n",
    "        'Kappa2', 'Kappa3', 'LabuteASA', 'Number_Aliphatic_Rings', 'Number_Aromatic_Rings', \n",
    "        'Number_Amide_Bonds', 'Number_Atom_Stereocenters', 'Number_BridgeHead_Atoms', 'Number_HBA', \n",
    "        'Number_HBD', 'Number_Hetero_Atoms', 'Number_Hetero_Cycles', 'Number_Rings', 'Number_Rotatable_Bonds', \n",
    "        'Number_Spiro', 'Number_Saturated_Rings', 'Number_Heavy_Atoms', 'Number_NH_OH', 'Number_N_O', \n",
    "        'Number_Valence_Electrons', 'Max_Partial_Charge', 'Min_Partial_Charge'\n",
    "    ])\n",
    "    \n",
    "    return pd.concat([df, desc_df], axis=1)\n",
    "\n",
    "# Compute descriptors for the entire dataset\n",
    "df = compute_descriptors_for_dataframe(df, 'unsat_SMILE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9e02ee9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "\n",
    "# Split data into initial training set and unlabeled pool\n",
    "initial_idx = np.random.choice(range(len(df)), size=500, replace=False)\n",
    "pool_idx = [i for i in range(len(df)) if i not in initial_idx]\n",
    "\n",
    "X = df.iloc[:, 5:].values  # Assuming descriptors start from the 5th column\n",
    "y = df['delta_H'].values\n",
    "\n",
    "X_initial = X[initial_idx]\n",
    "y_initial = y[initial_idx]\n",
    "X_pool = X[pool_idx]\n",
    "y_pool = y[pool_idx]\n",
    "\n",
    "# Initialize Gaussian Process\n",
    "kernel = DotProduct() + WhiteKernel()\n",
    "gp = GaussianProcessRegressor(kernel=kernel, random_state=1)\n",
    "\n",
    "# Train on the initial data\n",
    "gp.fit(X_initial, y_initial)\n",
    "\n",
    "# Make predictions on the pool\n",
    "predictions, std_dev = gp.predict(X_pool, return_std=True)\n",
    "\n",
    "# Let's say we want to add 100 least confident points to our training data\n",
    "uncertainty_idx = np.argsort(std_dev)[-100:]\n",
    "\n",
    "# Append the uncertain points to the initial data\n",
    "X_initial = np.vstack([X_initial, X_pool[uncertainty_idx]])\n",
    "y_initial = np.hstack([y_initial, y_pool[uncertainty_idx]])\n",
    "\n",
    "# Remove the uncertain points from the pool\n",
    "X_pool = np.delete(X_pool, uncertainty_idx, axis=0)\n",
    "y_pool = np.delete(y_pool, uncertainty_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "acaef1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/50 complete. Training set size: 1000 | Test MSE: 967.2802\n",
      "Iteration 2/50 complete. Training set size: 1400 | Test MSE: 956.0414\n",
      "Iteration 3/50 complete. Training set size: 1800 | Test MSE: 920.9549\n",
      "Iteration 4/50 complete. Training set size: 2200 | Test MSE: 898.9222\n",
      "Iteration 5/50 complete. Training set size: 2600 | Test MSE: 859.9096\n",
      "Iteration 6/50 complete. Training set size: 3000 | Test MSE: 845.8091\n",
      "Iteration 7/50 complete. Training set size: 3400 | Test MSE: 821.0274\n",
      "Iteration 8/50 complete. Training set size: 3800 | Test MSE: 798.2690\n",
      "Iteration 9/50 complete. Training set size: 4200 | Test MSE: 782.3044\n",
      "Iteration 10/50 complete. Training set size: 4600 | Test MSE: 768.7704\n",
      "Iteration 11/50 complete. Training set size: 5000 | Test MSE: 754.6201\n",
      "Iteration 12/50 complete. Training set size: 5400 | Test MSE: 740.5028\n",
      "Iteration 13/50 complete. Training set size: 5800 | Test MSE: 731.4334\n",
      "Iteration 14/50 complete. Training set size: 6200 | Test MSE: 719.1032\n",
      "Iteration 15/50 complete. Training set size: 6600 | Test MSE: 713.7537\n",
      "Iteration 16/50 complete. Training set size: 7000 | Test MSE: 705.5652\n",
      "Iteration 17/50 complete. Training set size: 7400 | Test MSE: 697.8816\n",
      "Iteration 18/50 complete. Training set size: 7800 | Test MSE: 690.5169\n",
      "Iteration 19/50 complete. Training set size: 8200 | Test MSE: 684.5604\n",
      "Iteration 20/50 complete. Training set size: 8600 | Test MSE: 678.4362\n",
      "Iteration 21/50 complete. Training set size: 9000 | Test MSE: 674.1407\n",
      "Iteration 22/50 complete. Training set size: 9400 | Test MSE: 671.0402\n",
      "Iteration 23/50 complete. Training set size: 9800 | Test MSE: 666.0919\n",
      "Iteration 24/50 complete. Training set size: 10200 | Test MSE: 661.9576\n",
      "Iteration 25/50 complete. Training set size: 10600 | Test MSE: 657.4957\n",
      "Iteration 26/50 complete. Training set size: 11000 | Test MSE: 655.5501\n",
      "Iteration 27/50 complete. Training set size: 11400 | Test MSE: 652.0684\n",
      "Iteration 28/50 complete. Training set size: 11800 | Test MSE: 648.5130\n",
      "Iteration 29/50 complete. Training set size: 12200 | Test MSE: 646.5554\n",
      "Iteration 30/50 complete. Training set size: 12600 | Test MSE: 643.5675\n",
      "Iteration 31/50 complete. Training set size: 13000 | Test MSE: 641.2924\n",
      "Iteration 32/50 complete. Training set size: 13400 | Test MSE: 638.7969\n",
      "Iteration 33/50 complete. Training set size: 13800 | Test MSE: 636.7714\n",
      "Iteration 34/50 complete. Training set size: 14200 | Test MSE: 634.4643\n",
      "Iteration 35/50 complete. Training set size: 14600 | Test MSE: 632.3346\n",
      "Iteration 36/50 complete. Training set size: 15000 | Test MSE: 630.3095\n",
      "Iteration 37/50 complete. Training set size: 15400 | Test MSE: 628.2024\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [96]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m n_to_add_each_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m400\u001b[39m  \u001b[38;5;66;03m# Existing value\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iterations):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Existing code...\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     \u001b[43mgp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_initial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_initial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     predictions, std_dev \u001b[38;5;241m=\u001b[39m gp\u001b[38;5;241m.\u001b[39mpredict(X_pool, return_std\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m     uncertainty_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(std_dev)[\u001b[38;5;241m-\u001b[39mn_to_add_each_iter:]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py:272\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_marginal_likelihood(theta, clone_kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# First optimize starting from theta specified in kernel\u001b[39;00m\n\u001b[1;32m    270\u001b[0m optima \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    271\u001b[0m     (\n\u001b[0;32m--> 272\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constrained_optimization\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m            \u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbounds\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m     )\n\u001b[1;32m    276\u001b[0m ]\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m# Additional runs are performed from log-uniform chosen initial\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;66;03m# theta\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_restarts_optimizer \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py:603\u001b[0m, in \u001b[0;36mGaussianProcessRegressor._constrained_optimization\u001b[0;34m(self, obj_func, initial_theta, bounds)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constrained_optimization\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj_func, initial_theta, bounds):\n\u001b[1;32m    602\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin_l_bfgs_b\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 603\u001b[0m         opt_res \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m            \u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m            \u001b[49m\u001b[43minitial_theta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m         _check_optimize_result(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m\"\u001b[39m, opt_res)\n\u001b[1;32m    611\u001b[0m         theta_opt, func_min \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_minimize.py:681\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    678\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    679\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 681\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    684\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    685\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_lbfgsb_py.py:362\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    356\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 362\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[1;32m    365\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:285\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m--> 285\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 251\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_optimize.py:76\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     75\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/optimize/_optimize.py:70\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 70\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py:262\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit.<locals>.obj_func\u001b[0;34m(theta, eval_gradient)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(theta, eval_gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_gradient:\n\u001b[0;32m--> 262\u001b[0m         lml, grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_marginal_likelihood\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_gradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclone_kernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mlml, \u001b[38;5;241m-\u001b[39mgrad\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py:574\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.log_marginal_likelihood\u001b[0;34m(self, theta, eval_gradient, clone_kernel)\u001b[0m\n\u001b[1;32m    572\u001b[0m inner_term \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mik,jk->ijk\u001b[39m\u001b[38;5;124m\"\u001b[39m, alpha, alpha)\n\u001b[1;32m    573\u001b[0m \u001b[38;5;66;03m# compute K^-1 of shape (n_samples, n_samples)\u001b[39;00m\n\u001b[0;32m--> 574\u001b[0m K_inv \u001b[38;5;241m=\u001b[39m \u001b[43mcho_solve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGPR_CHOLESKY_LOWER\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[43mK\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    576\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;66;03m# create a new axis to use broadcasting between inner_term and\u001b[39;00m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;66;03m# K_inv\u001b[39;00m\n\u001b[1;32m    579\u001b[0m inner_term \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m K_inv[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, np\u001b[38;5;241m.\u001b[39mnewaxis]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/scipy/linalg/_decomp_cholesky.py:208\u001b[0m, in \u001b[0;36mcho_solve\u001b[0;34m(c_and_lower, b, overwrite_b, check_finite)\u001b[0m\n\u001b[1;32m    205\u001b[0m overwrite_b \u001b[38;5;241m=\u001b[39m overwrite_b \u001b[38;5;129;01mor\u001b[39;00m _datacopied(b1, b)\n\u001b[1;32m    207\u001b[0m potrs, \u001b[38;5;241m=\u001b[39m get_lapack_funcs((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpotrs\u001b[39m\u001b[38;5;124m'\u001b[39m,), (c, b1))\n\u001b[0;32m--> 208\u001b[0m x, info \u001b[38;5;241m=\u001b[39m \u001b[43mpotrs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_b\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_b\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124millegal value in \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124mth argument of internal potrs\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    211\u001b[0m                      \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m-\u001b[39minfo)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Before active learning loop, split out a small test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# Modify your existing loop to also record performance on the test set\n",
    "mse_test = []\n",
    "\n",
    "n_iterations = 50  # Existing value\n",
    "n_to_add_each_iter = 400  # Existing value\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    # Existing code...\n",
    "    gp.fit(X_initial, y_initial)\n",
    "    predictions, std_dev = gp.predict(X_pool, return_std=True)\n",
    "    uncertainty_idx = np.argsort(std_dev)[-n_to_add_each_iter:]\n",
    "    X_initial = np.vstack([X_initial, X_pool[uncertainty_idx]])\n",
    "    y_initial = np.hstack([y_initial, y_pool[uncertainty_idx]])\n",
    "    X_pool = np.delete(X_pool, uncertainty_idx, axis=0)\n",
    "    y_pool = np.delete(y_pool, uncertainty_idx)\n",
    "\n",
    "    # New code: Record the model's performance on the test set\n",
    "    y_pred_test = gp.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred_test)\n",
    "    mse_test.append(mse)\n",
    "\n",
    "    print(f\"Iteration {i+1}/{n_iterations} complete. Training set size: {len(y_initial)} | Test MSE: {mse:.4f}\")\n",
    "\n",
    "# After the loop, visualize the model's performance over iterations\n",
    "plt.plot(range(n_iterations), mse_test, '-o')\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Mean Squared Error on Test Set\")\n",
    "plt.title(\"Model Performance Over Iterations\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bfa454df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nn_iterations = 10  # You can change this to any desired number\\nn_to_add_each_iter = 100  # Number of points to add from the pool to training set in each iteration\\n\\nfor i in range(n_iterations):\\n    # Train Gaussian Process on current training data\\n    gp.fit(X_initial, y_initial)\\n\\n    # Predict on the unlabeled pool\\n    predictions, std_dev = gp.predict(X_pool, return_std=True)\\n\\n    # Select points where the model is least confident (highest standard deviation)\\n    uncertainty_idx = np.argsort(std_dev)[-n_to_add_each_iter:]\\n\\n    # Append the uncertain points to the training data\\n    X_initial = np.vstack([X_initial, X_pool[uncertainty_idx]])\\n    y_initial = np.hstack([y_initial, y_pool[uncertainty_idx]])\\n\\n    # Remove the uncertain points from the pool\\n    X_pool = np.delete(X_pool, uncertainty_idx, axis=0)\\n    y_pool = np.delete(y_pool, uncertainty_idx)\\n\\n    # Optionally, print progress\\n    print(f\"Iteration {i+1}/{n_iterations} complete. Training set size: {len(y_initial)}\")\\n\\nprint(\"Active learning process complete!\")\\n'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "n_iterations = 10  # You can change this to any desired number\n",
    "n_to_add_each_iter = 100  # Number of points to add from the pool to training set in each iteration\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    # Train Gaussian Process on current training data\n",
    "    gp.fit(X_initial, y_initial)\n",
    "\n",
    "    # Predict on the unlabeled pool\n",
    "    predictions, std_dev = gp.predict(X_pool, return_std=True)\n",
    "\n",
    "    # Select points where the model is least confident (highest standard deviation)\n",
    "    uncertainty_idx = np.argsort(std_dev)[-n_to_add_each_iter:]\n",
    "\n",
    "    # Append the uncertain points to the training data\n",
    "    X_initial = np.vstack([X_initial, X_pool[uncertainty_idx]])\n",
    "    y_initial = np.hstack([y_initial, y_pool[uncertainty_idx]])\n",
    "\n",
    "    # Remove the uncertain points from the pool\n",
    "    X_pool = np.delete(X_pool, uncertainty_idx, axis=0)\n",
    "    y_pool = np.delete(y_pool, uncertainty_idx)\n",
    "\n",
    "    # Optionally, print progress\n",
    "    print(f\"Iteration {i+1}/{n_iterations} complete. Training set size: {len(y_initial)}\")\n",
    "\n",
    "print(\"Active learning process complete!\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bd9263be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Hydrogenation Enthalpy (kJ/mol H2) for the new molecule: 45.67651955256494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hassan/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Cc1cc2ccccc2o1\n",
    "\n",
    "new_molecule_smiles = \"c1cnc2ccc(C3CC3)cc2c1\"  # Replace with your SMILES string\n",
    "\n",
    "# Convert to RDKit mol object\n",
    "new_mol = Chem.MolFromSmiles(new_molecule_smiles)\n",
    "\n",
    "# Check if the conversion is successful\n",
    "if new_mol:\n",
    "    new_molecule_descriptors = evaluate_chem_mol(new_mol)\n",
    "else:\n",
    "    raise ValueError(\"Invalid SMILES string or molecule conversion failed.\")\n",
    "\n",
    "# Convert descriptors to a numpy array and reshape for single sample prediction\n",
    "new_molecule_descriptors = np.array(new_molecule_descriptors).reshape(1, -1)\n",
    "\n",
    "# Splitting the data into training and test sets\n",
    "train_data, test_data = train_test_split(df, test_size=0.1, random_state=42)\n",
    "\n",
    "# List of descriptor columns (you've defined these when you computed descriptors)\n",
    "descriptor_cols = [\n",
    "    'mol_sssr', 'clogp', 'mr', 'mw', 'tpsa', 'Chi0n', 'Chi1n', 'Chi2n', 'Chi3n', 'Chi4n', \n",
    "    'Chi0v', 'Chi1v', 'Chi2v', 'Chi3v', 'Chi4v', 'fracsp3', 'Hall_Kier_Alpha','Kappa1', \n",
    "    'Kappa2', 'Kappa3', 'LabuteASA', 'Number_Aliphatic_Rings', 'Number_Aromatic_Rings', \n",
    "    'Number_Amide_Bonds', 'Number_Atom_Stereocenters', 'Number_BridgeHead_Atoms', 'Number_HBA', \n",
    "    'Number_HBD', 'Number_Hetero_Atoms', 'Number_Hetero_Cycles', 'Number_Rings', 'Number_Rotatable_Bonds', \n",
    "    'Number_Spiro', 'Number_Saturated_Rings', 'Number_Heavy_Atoms', 'Number_NH_OH', 'Number_N_O', \n",
    "    'Number_Valence_Electrons', 'Max_Partial_Charge', 'Min_Partial_Charge'\n",
    "]\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data descriptors\n",
    "scaler.fit(train_data[descriptor_cols])\n",
    "\n",
    "new_molecule_descriptors_scaled = scaler.transform(new_molecule_descriptors)\n",
    "\n",
    "\n",
    "predicted_delta_H = gp.predict(new_molecule_descriptors_scaled)\n",
    "print(f\"Predicted Hydrogenation Enthalpy (kJ/mol H2) for the new molecule: {predicted_delta_H[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d279bd91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b5eb56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce64bc2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f12e138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea4de7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
